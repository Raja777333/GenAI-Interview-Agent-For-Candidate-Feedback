# GenAI-Interview-Agent-For-Candidate-Feedback
GenAI Interview Agent uses Flan-T5 and semantic matching to automate technical interview feedback, scoring answers and offering strengths, weaknesses, and improvement tips, making assessments objective and scalable.

ğŸ¯ Use Case: AI-Powered Interview AgentÂ¶
Hiring technical talent often involves manually assessing candidate answers during interviews.
This process is often:


ğŸŒ Slow
ğŸ™… Subjective
ğŸ” Inconsistent
ğŸ’¡ What This Notebook Does
This notebook demonstrates a GenAI-powered Interview Agent using a local large language model (LLM).
It can:


ğŸ§  1. Ask technical questions from a curated dataset
ğŸ’¬ 2. Accept a candidateâ€™s answer (real or synthetic)
ğŸ§¾ 3. Evaluate the response with:


âœ… Strengths
âŒ Weaknesses
ğŸ“ˆ Suggestions
ğŸ§  Score out of 10
âš™ï¸ Powered By
ğŸ” google/flan-t5-large LLM
ğŸ¤— Hugging Face Transformers pipeline
âœ¨ Few-shot prompting + structured feedback generation
ğŸ“Š Synthetic dataset creation for scalable evaluation

Project Overview
This project simulates an AI-driven interview evaluation system. It leverages Generative AI models to assess candidate responses to technical interview questions and provide feedback. The process includes generating realistic candidate answers, comparing them to ideal answers, and offering personalized suggestions for improvement.

Key features of the project:

Feedback Generation: Using the Flan-T5 Large model, it generates structured feedback based on the candidate's answer, suggesting areas for improvement.
Semantic Similarity Matching: A sentence transformer model calculates semantic similarity between ideal and candidate answers to provide more accurate feedback.
Few-shot Prompting: Utilizes few-shot prompting to guide the model in generating helpful and relevant feedback based on examples of previous interview evaluations.
LoRA Fine-Tuning: Fine-tunes the model with a custom LoRA adapter to enhance its performance in generating specialized feedback.
This approach offers a comprehensive solution to automate the feedback process for interview assessments and aims to make interview evaluations more efficient, consistent, and informative for both candidates and interviewers.

GenAI Capabilities Used
The notebook leverages several GenAI capabilities:

Text Generation âœï¸: 
Uses Flan-T5 Large model to generate structured feedback on interview responses, controlling output generation based on the question and ideal answer.

Few-shot Prompting ğŸ¯: 
Implements few-shot prompting techniques to guide the model in generating structured feedback, using example-based input for better results.

Document Understanding ğŸ“„: 
Analyzes interview questions and candidate answers to generate relevant and coherent feedback based on ideal answers.

Semantic Similarity Matching ğŸ”: 
Employs a sentence transformer model to calculate the semantic similarity between the candidateâ€™s answer and ideal answers for more accurate feedback.

Embeddings ğŸ§ : 
Converts the candidateâ€™s answer and ideal response into embeddings for semantic comparison using vector space representations.

Controlled Generation ğŸ›ï¸: 
Generates feedback with structured suggestions and scores, ensuring output aligns with the defined structure for improvement.

Fine-tuning ğŸ”§: 
Implements LoRA (Low-Rank Adaptation) to fine-tune a model for personalized interview feedback generation.

GenAI Evaluation ğŸ”: 
This project uses GenAI evaluation to assess candidate answers against ideal responses. It leverages pre-trained models like Flan-T5 for structured feedback and semantic similarity matching to evaluate the relevance and quality of answers, ensuring consistent and data-driven insights.
